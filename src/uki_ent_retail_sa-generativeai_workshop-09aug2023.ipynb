{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a5278e-4064-4cbb-989d-33228b6e0e49",
   "metadata": {},
   "source": [
    "# <div> <b> UKIR ENT Retail SA Workshop - 09August2023 - Generative AI </b> </div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b93e1-b222-449b-aa18-cc00c90c09aa",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Use the notebook environment: PyTorch 1.13  Python 3.9 GPU Optimized | ml.g4dn.xlarge\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588c6c0-cc07-491e-aeed-51e3ad8cbb23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e4af2-a3e5-4731-b98b-fc2c6fc2b075",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> \n",
    "    - Install required core packages used in rest of the sections of the notebook.\n",
    "    - Set global parameters required for the lab.\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19af01cf-4539-488b-a5e8-0d92e372858d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets==7.0.0 --quiet\n",
    "!pip install --upgrade sagemaker --quiet\n",
    "!pip install langchain --quiet\n",
    "!pip install ipyparallel --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a4a9de-3421-4355-a00b-de133ce65326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sm_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1aad71b-7d89-45c7-965a-6437c0623aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'huggingface-text2text-flan-t5-xl' # this is the default model for this lab\n",
    "EMBEDDING_MODEL_ID = 'huggingface-textembedding-gpt-j-6b-fp16' # this is the default model for this lab\n",
    "MODEL_VERSION = '*'\n",
    "INF_INSTANCE_TYPE = 'ml.g5.2xlarge'\n",
    "INF_INSTANCE_COUNT = 1\n",
    "INF_IMAGE_SCOPE = 'inference'\n",
    "TRN_INSTANCE_TYPE = 'ml.g5.12xlarge'\n",
    "TRN_INSTANCE_COUNT = 1\n",
    "TRN_IMAGE_SCOPE = 'training'\n",
    "MODEL_DATA_DOWNLOAD_TIMEOUT = 3600  # in seconds\n",
    "CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT = 3600\n",
    "EBS_VOLUME_SIZE = 256  # in GB\n",
    "CONTENT_TYPE = 'application/json'\n",
    "MODEL_ENDPOINT_PREFIX = 'uki-ent-ret-sa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51559a9f-22ed-4033-89bb-d62d314d7d82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 1\n",
    "<h1><b>Deploying Models</b></h1>\n",
    "<h2>\n",
    "   Deploy the state-of-the-art pre-trained models **[FLAN T5 models](https://huggingface.co/docs/transformers/model_doc/flan-t5)** and query the endpoint to generate response from the base model. Also deploy embedding model to generate embeddings for Retrieval Augmented Generation\n",
    "    \n",
    "</h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782384d-6679-4ac9-a49a-13da7189d53a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **STEPS**\n",
    "- [1.a Select a model](#1.a-Select-a-model)\n",
    "- [1.b Retrieve Artifacts & Deploy an Endpoint](#1.b-Retrieve-Artifacts-&-Deploy-an-Endpoint)\n",
    "- [1.c Query endpoint and parse response](#1.c-Query-endpoint-and-parse-response)\n",
    "- [1.d Advanced features: How to use various parameters to control the generated text](#1.d-Advanced-features:-How-to-use-various-advanced-parameters-to-control-the-generated-text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a862e1-ddc9-470c-a6c6-a11272b8fea9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1.a Select a pre-trained model**\n",
    "***\n",
    "You can continue with the default model, or can choose a different model from the dropdown generated upon running the next cell. A complete list of SageMaker pre-trained models can also be accessed at [SageMaker pre-trained Models](https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html#).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074fb133-286d-41ce-b36c-be43822ae290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# Retrieves all Text Generation models available by SageMaker Built-In Algorithms.\n",
    "filter_value = \"task == text2text\"\n",
    "text_generation_models = list_jumpstart_models(filter=filter_value)\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "model_dropdown = Dropdown(\n",
    "    options=text_generation_models,\n",
    "    value=MODEL_ID,\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa9823a-07f7-4f0b-b000-a03ee541b134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6af995d61fc4cbd9f3ff63605e5ee70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f144d67-3f65-44cc-aadd-dc79c1c199d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    The current notebook is only tested against the model : <b> huggingface-text2text-flan-t5-xl </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287971fa-e471-4315-9582-e06a001628e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_version=\"*\" fetches the latest version of the model\n",
    "MODEL_ID, MODEL_VERSION = model_dropdown.value, \"*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55064aa-c983-46fd-b559-854564885964",
   "metadata": {},
   "source": [
    "Later on for RAG we will need an embeddings model to generate embeddings of our prompts and support data so we select that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1071a55-257e-4a04-81a0-2ef8b25134dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieves all Text Generation models available by SageMaker Built-In Algorithms.\n",
    "filter_value = \"task == textembedding\"\n",
    "embedding_models = list_jumpstart_models(filter=filter_value)\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "embedding_model_dropdown = Dropdown(\n",
    "    options=embedding_models,\n",
    "    value=EMBEDDING_MODEL_ID,\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb32c9d3-3846-4018-8835-2a2b7a81a553",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815177cfeca346efa4ea324045e3f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(embedding_model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fbbe05-800a-45e6-9c8a-2a3ec241c4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_version=\"*\" fetches the latest version of the model\n",
    "EMBEDDING_MODEL_ID, MODEL_VERSION = embedding_model_dropdown.value, \"*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47534cab-6f80-44ad-9eec-366b14413596",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1.b Retrieve Artifacts & Deploy an Endpoint for base models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b494f8-637a-4866-a358-b65bd15ed18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a unique endpoint name for the current model deployment. Add current timestamp as the suffix if needed\n",
    "base_endpoint_name = f'{MODEL_ENDPOINT_PREFIX}-base-{MODEL_ID}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d62b07-0e17-4291-ad75-e3e46a5684c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the inference docker container uri.\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=INF_IMAGE_SCOPE,\n",
    "    model_id=MODEL_ID,\n",
    "    model_version=MODEL_VERSION,\n",
    "    instance_type=INF_INSTANCE_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "307e52c9-7194-4782-b848-4257315cadf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the model uri.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=MODEL_ID, model_version=MODEL_VERSION, model_scope=INF_IMAGE_SCOPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180d7e1-65a9-43d3-b2fa-4e1ea26c3a28",
   "metadata": {},
   "source": [
    "#### **huggingface-text2text-flan-t5-xl** is already packed with the inference script and model artifacts, so the `source_dir` argument and entryPoint script to the Model are not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a755bc99-7cae-44f7-ad76-5d0a204de575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the SageMaker model instance. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=base_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d87ed2c-cad1-4add-b37e-8854d9fb3992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a unique endpoint name for the current model deployment. Add current timestamp as the suffix if needed\n",
    "base_embedding_endpoint_name = f'{MODEL_ENDPOINT_PREFIX}-base-{EMBEDDING_MODEL_ID}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "235b68d6-b54d-473e-b07c-12640e7c2155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the inference docker container uri.\n",
    "deploy_embedding_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=INF_IMAGE_SCOPE,\n",
    "    model_id=EMBEDDING_MODEL_ID,\n",
    "    model_version=MODEL_VERSION,\n",
    "    instance_type=INF_INSTANCE_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4afed941-2ce6-463b-a9c0-014d887cadbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the model uri.\n",
    "model_embedding_uri = model_uris.retrieve(\n",
    "    model_id=EMBEDDING_MODEL_ID, model_version=MODEL_VERSION, model_scope=INF_IMAGE_SCOPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26c12ab1-f25f-484d-9d96-9a2f08813176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the SageMaker model instance. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "\n",
    "embedding_model = Model(\n",
    "    image_uri=deploy_embedding_image_uri,\n",
    "    model_data=model_embedding_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=base_embedding_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edcc50b-3583-4578-a42a-34eddf9474d2",
   "metadata": {},
   "source": [
    "Now we deploy both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3796f3cd-5438-4185-b3e1-aa9610feb791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "# deploy the Model\n",
    "base_model_predictor = model.deploy(\n",
    "    initial_instance_count=INF_INSTANCE_COUNT,\n",
    "    instance_type=INF_INSTANCE_TYPE,\n",
    "    endpoint_name=base_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31456b6a-dd83-4aa2-bd2f-42e30d0f8e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# deploy the Model\n",
    "base_embedding_model_predictor = embedding_model.deploy(\n",
    "    initial_instance_count=INF_INSTANCE_COUNT,\n",
    "    instance_type=INF_INSTANCE_TYPE,\n",
    "    endpoint_name=base_embedding_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1fe9a-5c90-43fe-88a7-66dcad5224c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1.c Query endpoint and parse response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f03f62ff-327c-4991-8722-1b03fcbf15d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "\n",
    "def query_endpoint(encoded_text, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/x-text\", Body=encoded_text\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    generated_text = model_predictions[\"generated_text\"]\n",
    "    return generated_text\n",
    "\n",
    "def my_query_endpoint(query):\n",
    "    payload = {\n",
    "        \"text_inputs\": query,\n",
    "        \"max_length\": 5000,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        \"do_sample\": False,\n",
    "        \"temperature\": 0.2,\n",
    "    }\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=base_endpoint_name, ContentType='application/json', Body=json.dumps(payload).encode('utf-8'))\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_completion(query):\n",
    "    return parse_response_multiple_texts(\n",
    "        my_query_endpoint(query)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "594cce31-7515-4a66-b06b-3affe843ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:\n",
      "input text: Translate to German:  My name is SageMaker Jumpstart\n",
      "generated text: \u001b[1mIch bin SageMaker Jumpstart.\u001b[0m\n",
      "\n",
      "Inference:\n",
      "input text: A step by step guide to deploy a large language model:\n",
      "generated text: \u001b[1mStep 1: Create a large language model. Step 2: Create a large language model\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "text1 = \"Translate to German:  My name is SageMaker Jumpstart\"\n",
    "text2 = \"A step by step guide to deploy a large language model:\"\n",
    "\n",
    "\n",
    "for text in [text1, text2]:\n",
    "    query_response = query_endpoint(text.encode(\"utf-8\"), endpoint_name=base_endpoint_name)\n",
    "    generated_text = parse_response(query_response)\n",
    "    print(\n",
    "        f\"Inference:{newline}\"\n",
    "        f\"input text: {text}{newline}\"\n",
    "        f\"generated text: {bold}{generated_text}{unbold}{newline}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f883a-60c1-43bf-87d0-8946735a6564",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1.d. Advanced features: How to use various advanced parameters to control the generated text**\n",
    "\n",
    "***\n",
    "This model also supports many advanced parameters while performing inference. They include:\n",
    "\n",
    "* **max_length:** Model generates text until the output length (which includes the input context length) reaches `max_length`. If specified, it must be a positive integer.\n",
    "* **num_return_sequences:** Number of output sequences returned. If specified, it must be a positive integer.\n",
    "* **num_beams:** Number of beams used in the greedy search. If specified, it must be integer greater than or equal to `num_return_sequences`.\n",
    "* **no_repeat_ngram_size:** Model ensures that a sequence of words of `no_repeat_ngram_size` is not repeated in the output sequence. If specified, it must be a positive integer greater than 1.\n",
    "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "* **early_stopping:** If True, text generation is finished when all beam hypotheses reach the end of sentence token. If specified, it must be boolean.\n",
    "* **do_sample:** If True, sample the next word as per the likelihood. If specified, it must be boolean.\n",
    "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
    "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
    "* **seed:** Fix the randomized state for reproducibility. If specified, it must be an integer.\n",
    "\n",
    "We may specify any subset of the parameters mentioned above while invoking an endpoint. Next, we show an example of how to invoke endpoint with these arguments\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd2a803f-bce9-41ca-80f9-8754e18769c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Create a new EC2 instance on AWS. Select an instance type. Enter the instance size.']\n"
     ]
    }
   ],
   "source": [
    "# Input must be a json\n",
    "payload = {\n",
    "    \"text_inputs\": \"Tell me the steps to create an ec2 instance on AWS cloud\",\n",
    "    \"max_length\": 100,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 20,\n",
    "    \"top_p\": 0.8,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\":0.8\n",
    "}\n",
    "\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    json.dumps(payload).encode(\"utf-8\"), endpoint_name=base_endpoint_name\n",
    ")\n",
    "\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    model_predictions = json.loads(query_response[\"Body\"].read())\n",
    "    generated_text = model_predictions[\"generated_texts\"]\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "generated_texts = parse_response_multiple_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83964f8-e127-4981-b1f2-b716c1888fd2",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Text Summarization**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3ce79ef-0bdc-4661-96f4-70d010ccbe2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"CodeWhisperer is an AI coding companion that generates real-time, single-line or full-function code suggestions in your Integrated Development Environment (IDE) to help you quickly build software. With CodeWhisperer, you can write a comment in natural language that outlines a specific task in English, such as “Upload a file with server-side encryption.” Based on this information, CodeWhisperer recommends one or more code snippets directly in the IDE that can accomplish the task. You can quickly and easily accept the top suggestion (tab key), view more suggestions (arrow keys), or continue writing your own code. You should always review a code suggestion before accepting them, and you may need to edit it to ensure it does exactly what you intended. CodeWhisperer helps accelerate software development by providing code suggestions that reduce total development effort and allow more time for ideation, complex problem solving, and writing differentiated code. In addition to general purpose code suggestions, CodeWhisperer has additional training to provide code suggestions for using AWS APIs. CodeWhisperer can also help you improve application security by helping detect and remediate security vulnerabilities. As you are writing code, CodeWhisperer analyzes the English language comments and surrounding code to infer what code is needed to complete the task at hand. CodeWhisperer suggests one or more code snippets directly in the code editor, accelerating you as you code. The code suggestions provided by CodeWhisperer are based on a large language models (LLMs) trained on billions of lines of code, including Amazon and open-source code. You can quickly and more easily accept the top suggestion (tab key), view more suggestions (arrow keys), or continue writing your own code. Always review a code suggestion before accepting it, and you may need to edit it to ensure that it does exactly what you intended.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e33527e-c61e-4414-a1b1-707fc831ad4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of return sequences are set as 1\u001b[0m\n",
      "\n",
      "\u001b[1m For prompt: 'Briefly summarize this sentence: {text}'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer is an AI coding companion that generates real-time, single-line or full-function code suggestions in your Integrated Development Environment (IDE). With CodeWhisperer, you can write a comment\n",
      "\n",
      "\u001b[1m For prompt: 'Write a short summary for this text: {text}'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: Download CodeWhisperer to accelerate software development with code suggestions.\n",
      "\n",
      "\u001b[1m For prompt: 'Generate a short summary this sentence:\n",
      "{text}'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer generates intelligent coding suggestions to help software developers accelerate development. With CodeWhisperer, you can write a comment that outlines a specific task in English. CodeWhisperer then recommends\n",
      "\n",
      "\u001b[1m For prompt: '{text}\n",
      "\n",
      "Write a brief summary in a sentence or less'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer, a new technology that combines machine learning and deep learning, offers developers real-time, single-line or full-function code suggestions in their IDE\n",
      "\n",
      "\u001b[1m For prompt: '{text}\n",
      "Summarize the aforementioned text in a single phrase.'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: Get CodeWhisperer.\n",
      "\n",
      "\u001b[1m For prompt: '{text}\n",
      "Can you generate a short summary of the above paragraph?'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer is an AI coding companion that generates real-time, single-line or full-function code suggestions in your Integrated Development Environment (IDE) to help you quickly build software.\n",
      "\n",
      "\u001b[1m For prompt: 'Write a sentence based on this summary: {text}'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer is an intelligent machine learning companion that generates code suggestions in your IDE to help you quickly build software. With CodeWhisperer, you can write a comment in natural language that outlines a specific\n",
      "\n",
      "\u001b[1m For prompt: 'Write a sentence based on '{text}''\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer is an AI coding companion that generates real-time, single-line or full-function code suggestions in your Integrated Development Environment (IDE) to help you quickly build software. With CodeWhisperer\n",
      "\n",
      "\u001b[1m For prompt: 'Summarize this article:\n",
      "\n",
      "{text}'\u001b[0m\n",
      "\n",
      "\u001b[1m The 1 summarized results are\u001b[0m:\n",
      "\n",
      "\u001b[1mResult 0\u001b[0m: CodeWhisperer is a real-time AI code companion. Write natural language in your code editor. Use CodeWhisperer’s code suggestions as you write code. Review code suggestions before accepting them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Briefly summarize this sentence: {text}\",\n",
    "    \"Write a short summary for this text: {text}\",\n",
    "    \"Generate a short summary this sentence:\\n{text}\",\n",
    "    \"{text}\\n\\nWrite a brief summary in a sentence or less\",\n",
    "    \"{text}\\nSummarize the aforementioned text in a single phrase.\",\n",
    "    \"{text}\\nCan you generate a short summary of the above paragraph?\",\n",
    "    \"Write a sentence based on this summary: {text}\",\n",
    "    \"Write a sentence based on '{text}'\",\n",
    "    \"Summarize this article:\\n\\n{text}\",\n",
    "]\n",
    "\n",
    "num_return_sequences = 1\n",
    "parameters = {\n",
    "    \"max_length\": 50,\n",
    "    \"num_return_sequences\": num_return_sequences,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "print(f\"{bold}Number of return sequences are set as {num_return_sequences}{unbold}{newline}\")\n",
    "for each_prompt in prompts:\n",
    "    payload = {\"text_inputs\": each_prompt.replace(\"{text}\", text), **parameters}\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=base_endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response_multiple_texts(query_response)\n",
    "    print(f\"{bold} For prompt: '{each_prompt}'{unbold}{newline}\")\n",
    "    print(f\"{bold} The {num_return_sequences} summarized results are{unbold}:{newline}\")\n",
    "    for idx, each_generated_text in enumerate(generated_texts):\n",
    "        print(f\"{bold}Result {idx}{unbold}: {each_generated_text}{newline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fcc23-f800-4986-84a6-c5505c624a7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### **Question and Answering**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0688ddfb-1e0e-4157-bb93-038ec02ede90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = \"\"\"The newest and most innovative Kindle yet lets you take notes on millions of books and documents, write lists and journals, and more. \n",
    "\n",
    "For readers who have always wished they could write in their eBooks, Amazon’s new Kindle lets them do just that. The Kindle Scribe is the first Kindle for reading and writing and allows users to supplement their books and documents with notes, lists, and more.\n",
    "\n",
    "Here’s everything you need to know about the Kindle Scribe, including frequently asked questions.\n",
    "\n",
    "The Kindle Scribe makes it easy to read and write like you would on paper \n",
    "\n",
    "The Kindle Scribe features a 10.2-inch, glare-free screen (the largest of all Kindle devices), crisp 300 ppi resolution, and 35 LED front lights that automatically adjust to your environment. Further personalize your experience with the adjustable warm light, font sizes, line spacing, and more.\n",
    "\n",
    "It comes with your choice of the Basic Pen or the Premium Pen, which you use to write on the screen like you would on paper. They also attach magnetically to your Kindle and never need to be charged. The Premium Pen includes a dedicated eraser and a customizable shortcut button.\n",
    "\n",
    "The Kindle Scribe has the most storage options of all Kindle devices: choose from 8 GB, 16 GB, or 32 GB to suit your level of reading and writing.\n",
    "\"\"\"\n",
    "question = \"what are the key features of new Kindle?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74c6973f-06df-4be8-81f0-426e88b41217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m The reasoning result is\u001b[0m: '['a.']'\n",
      "\n",
      "\u001b[1m The reasoning result is\u001b[0m: '['Kindle Scribe is the first Kindle for reading and writing and allows users to supplement their books and documents with notes, lists, and more']'\n",
      "\n",
      "\u001b[1m The reasoning result is\u001b[0m: '['it’s got a huge, glare-free screen']'\n",
      "\n",
      "\u001b[1m The reasoning result is\u001b[0m: '['lets you take notes']'\n",
      "\n",
      "\u001b[1m The reasoning result is\u001b[0m: '['lets you take notes on millions of books and documents, write lists and journals, and more.']'\n",
      "\n",
      "\u001b[1m The reasoning result is\u001b[0m: '['The Kindle Scribe has the most storage options of all Kindle devices']'\n",
      "\n",
      "\u001b[1m The reasoning result is\u001b[0m: '['The Premium Pen is more powerful than ever, allowing you to take notes on paper-sized pages. You can also connect an external digital pen to your Kindle for on-the-go writing and drawing. How does the Kindle Scri']'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"\"\"Answer based on context:\\n\\n{context}\\n\\n{question}\"\"\",\n",
    "    \"\"\"{context}\\n\\nAnswer this question based on the article: {question}\"\"\",\n",
    "    \"\"\"{context}\\n\\n{question}\"\"\",\n",
    "    \"\"\"{context}\\nAnswer this question: {question}\"\"\",\n",
    "    \"\"\"Read this article and answer this question {context}\\n{question}\"\"\",\n",
    "    \"\"\"{context}\\n\\nBased on the above article, answer a question. {question}\"\"\",\n",
    "    \"\"\"Write an article that answers the following question: {question} {context}\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"max_length\": 50,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "\n",
    "for each_prompt in prompts:\n",
    "    input_text = each_prompt.replace(\"{context}\", context)\n",
    "    input_text = input_text.replace(\"{question}\", question)\n",
    "    #print(f\"{bold} For prompt{unbold}: '{each_prompt}'{newline}\")\n",
    "    payload = {\"text_inputs\": input_text, **parameters}\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=base_endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response_multiple_texts(query_response)\n",
    "    print(f\"{bold} The reasoning result is{unbold}: '{generated_texts}'{newline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1c8cf-8268-49da-8f3a-9c053fcb26b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### **Imaginary article generation based on a title**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55d67949-e573-42d1-8199-b29c2129ba47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = \"AnyCompany business has a new product category coming up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b8b7309-544f-45f1-9412-cb8d531a6ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m The reasoning result is\u001b[0m: '['nn\"I love you all and can\\'t wait to work with you\"n']'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"\"\"Title: \\\"{title}\\\"\\\\nGiven the above title of an imaginary article, imagine the article.\\\\n\"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"max_length\": 5000,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "\n",
    "for each_prompt in prompts:\n",
    "    input_text = each_prompt.replace(\"{title}\", title)\n",
    "    #print(f\"{bold} For prompt{unbold}: '{input_text}'{newline}\")\n",
    "    payload = {\"text_inputs\": input_text, **parameters}\n",
    "    query_response = query_endpoint_with_json_payload(\n",
    "        json.dumps(payload).encode(\"utf-8\"), endpoint_name=base_endpoint_name\n",
    "    )\n",
    "    generated_texts = parse_response_multiple_texts(query_response)\n",
    "    print(f\"{bold} The reasoning result is{unbold}: '{generated_texts}'{newline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde65a2f-dec9-4421-957b-bf9ae719c519",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 2\n",
    "---\n",
    "<h1><b> Retrieval Augmented Generation(RAG) </b></h1>\n",
    "\n",
    "<h2>\n",
    "   Implementing RAG with a local vector store index using langchain and FAISS.\n",
    "    <br/>\n",
    "    \n",
    "</h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920476cb-ecb7-4ace-8cfb-1760f2295a33",
   "metadata": {},
   "source": [
    "### **STEPS**\n",
    "- [2.a Create text2textgeneration(T2T) llm contenthandler](#2.a-Create-text2textgeneration-contenthandler)\n",
    "- [2.b Create embedding llm contenthandler](#2.b-Create-embediing-contenthandler)\n",
    "- [2.c Generating embeddings and populating index](#2.c-Generating-embediing-and-populating-index)\n",
    "- [2.d Querying t2t llm using RAG ](#2.D-Querying-t2t-llm-using-RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f264ec6-c590-42ab-ac30-a0134bc1ebf3",
   "metadata": {},
   "source": [
    "Before we proceed to the next steps, let's ensure that we have the necessary libraries installed. We will need the `langchain` library for the following steps. If it's not already installed, we can install it using pip.\n",
    "\n",
    "The `langchain` library is a Python library that provides utilities for working with large language models. It includes utilities for creating prompts, querying endpoints, parsing responses, and more. We will use this library in the following steps to interact with our SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1744bf05-4cf8-40f7-b9dc-cc6b2cb3cbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\u001b[33m\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2619 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2925 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]     \u001b[0m\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [29.3 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1091 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB][0m\u001b[33m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [32.0 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1391 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3420 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2789 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Fetched 27.8 MB in 2s (15.9 MB/s)33m                       \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "103 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libmagic-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 103 not upgraded.\n",
      "Need to get 88.3 kB of archives.\n",
      "After this operation, 377 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libmagic-dev amd64 1:5.38-4 [88.3 kB]\n",
      "Fetched 88.3 kB in 0s (1219 kB/s)    \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libmagic-dev:amd64.\n",
      "(Reading database ... 45111 files and directories currently installed.)\n",
      "Preparing to unpack .../libmagic-dev_1%3a5.38-4_amd64.deb ...\n",
      "Unpacking libmagic-dev:amd64 (1:5.38-4) ...\n",
      "Setting up libmagic-dev:amd64 (1:5.38-4) ...\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt-get install libmagic-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e8e8d33-06a4-4faa-b529-f887d33ec86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade python-magic unstructured faiss-cpu pandas --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f44b96-d882-4d3e-a699-3b62c3ae2a59",
   "metadata": {},
   "source": [
    "Now, let's import some necessary modules from the `langchain` library.\n",
    "\n",
    "- `PromptTemplate`: This class is used to create a template for the prompts that we will pass to the language model. \n",
    "- `SagemakerEndpoint`: This class is used to interact with the SageMaker endpoint.\n",
    "- `LLMContentHandler`: This class is used to handle the content that we send to and receive from the language model.\n",
    "- `load_qa_chain`: This function is used to load a question-answering chain. A chain is a sequence of transformations applied to the input to generate an answer.\n",
    "- `Document`: This class is used to create documents that the language model can use to find the answer to a question.\n",
    "- `EmbeddingsContentHandler`: This class is used to handle the content that we send to and receive from the embedding model.\n",
    "- `SagemakerEndpointEmbeddings`: This class is used to interact with the SageMaker embeddings enpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be9eed96-771b-40f6-81c5-4e70171651e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain, LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "import json\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4dab7-ab82-46c5-a116-85f869f0e601",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2.a Creating text2textgeneration llm contenthandler**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb730b0-dea5-464d-8d0b-855b727a5e3e",
   "metadata": {},
   "source": [
    "We will now create a content handler for the language model to transform input to a format that the SageMaker endpoint expects and output to a form that the language model class expects. We will also define some parameters for the model.\n",
    "\n",
    "The `ContentHandler` class is a subclass of the `LLMContentHandler` class. It defines two methods:\n",
    "\n",
    "- `transform_input`: This method takes a prompt and a dictionary of model parameters as input, and returns the input in a format that the SageMaker endpoint expects. In this case, it converts the input to a JSON string and encodes it to bytes.\n",
    "- `transform_output`: This method takes the output from the SageMaker endpoint and returns it in a form that the language model class expects. In this case, it decodes the output from bytes to a string, parses the JSON, and returns the 'generated_texts' field.\n",
    "\n",
    "The `parameters` dictionary defines the parameters that we will use when querying the language model. These parameters control the behavior of the language model, such as the maximum length of the generated text, the number of sequences to return, and the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4960f8-2378-4760-bbc4-21e32efe58ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_length\": 5000,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.01,\n",
    "}\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json['generated_texts'][0]\n",
    "    \n",
    "\n",
    "\n",
    "llm_content_handler = ContentHandler()\n",
    "sm_llm=SagemakerEndpoint(\n",
    "            endpoint_name=base_endpoint_name,\n",
    "            region_name=\"eu-central-1\",\n",
    "            model_kwargs=parameters,\n",
    "            content_handler=llm_content_handler,\n",
    "        )\n",
    "creative_llm=SagemakerEndpoint(\n",
    "            endpoint_name=base_endpoint_name,\n",
    "            region_name=\"eu-central-1\",\n",
    "            model_kwargs={\n",
    "                \"max_length\": 5000,\n",
    "                \"num_return_sequences\": 1,\n",
    "                \"top_k\": 250,\n",
    "                \"top_p\": 0.95,\n",
    "                \"do_sample\": False,\n",
    "                \"temperature\": 2.5\n",
    "            },\n",
    "            content_handler=llm_content_handler,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d053b-dc8f-4cb7-9bb0-3f4fe9dd652e",
   "metadata": {},
   "source": [
    "Next, we will define a prompt template and load a chain. \n",
    "\n",
    "The prompt template is used to format the input to the language model. It accepts a set of parameters from the user that can be used to generate a prompt for a language model. \n",
    "\n",
    "The question answering chain is a sequence of transformations applied to the input to generate an answer.\n",
    "\n",
    "The `PromptTemplate` class takes a template string and a list of input variables as arguments. The template string is a string that contains placeholders for the input variables. The placeholders are enclosed in curly braces `{}` and correspond to the names of the input variables. When we use the prompt template, we will replace the placeholders with the actual values of the input variables.\n",
    "\n",
    "The `chain` function loads a chain. A chain is a sequence of transformations applied to the input to generate an answer. Chains allow us to combine multiple components together to create a single, coherent application. For example, we can create a chain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. In this case, the chain includes the language model and the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0f3e299-bd26-409a-9cc2-e1c8507fe78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "            template=\"Use the following pieces of context to answer the question at the end.\\n{context}\\nQuestion: {question}\\nAnswer:\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "chain = load_qa_chain(\n",
    "        llm=sm_llm,\n",
    "        prompt=prompt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474b48b-de30-4473-b18a-725977b84cff",
   "metadata": {},
   "source": [
    "Now, let's test our question answering chain with a sample question and some context. The context is a list of documents that the model can use to find the answer to the question.\n",
    "\n",
    "The `chain` function takes a dictionary as input and returns the output of the chain. The input dictionary must contain the 'input_documents' and 'question' keys. The 'input_documents' key corresponds to a list of documents that the model can use to find the answer to the question. The 'question' key corresponds to the question that we want to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3bef16f-1ad4-48ac-9777-1f1447381141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'SageMaker'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which instances can I use with Managed Spot Training in SageMaker?\"\n",
    "\n",
    "input_documents = [Document(page_content=\"\")]\n",
    "\n",
    "chain({\"input_documents\": input_documents, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616e924-fa2f-47a9-a792-977cd32c7c30",
   "metadata": {},
   "source": [
    "#### The correct answer should show that all instances in Sagemaker can be used with Managed Spot Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e649aa0-8d77-460a-89a7-8664368953bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2.b Creating text2textgeneration llm contenthandler**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f3d06-fdc5-4663-9cf8-b82c3693e472",
   "metadata": {},
   "source": [
    "Next, we will create a content handler for embeddings to transform a format that the SageMaker endpoint expects and output to a form that the embeddings class expects.\n",
    "\n",
    "The `SagemakerEndpointEmbeddingsJumpStart` class is a subclass of the `SagemakerEndpointEmbeddings` class. It defines the `embed_documents` method, which computes document embeddings using a SageMaker Inference Endpoint. The method takes a list of texts and a chunk size as input, and returns a list of embeddings.\n",
    "\n",
    "The `ContentHandler` class is a subclass of the `EmbeddingsContentHandler` class. It defines two methods:\n",
    "\n",
    "- `transform_input`: This method takes a prompt and a dictionary of model parameters as input, and returns the input in a format that the SageMaker endpoint expects. In this case, it converts the input to a JSON string and encodes it to bytes.\n",
    "- `transform_output`: This method takes the output from the SageMaker endpoint and returns it in a form that the embeddings class expects. In this case, it decodes the output from bytes to a string, parses the JSON, and returns the 'embedding' field.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b1b679d-7e53-4556-954e-d5af3756fed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(self, texts: List[str], chunk_size: int = 5) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            response = self._embedding_func(texts[i : i + _chunk_size])\n",
    "            print\n",
    "            results.extend(response)\n",
    "        return results\n",
    "\n",
    "class ContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        embeddings = response_json[\"embedding\"]\n",
    "        return embeddings\n",
    "embeddings_content_handler=ContentHandler()\n",
    "embeddings = SagemakerEndpointEmbeddingsJumpStart(\n",
    "    endpoint_name=base_embedding_endpoint_name,\n",
    "    region_name=\"eu-central-1\",\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feedfdf-79b4-44d5-8e96-2908e6918186",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2.c Generating embeddings and populating index**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c5a62-6045-44e3-8610-2cf6cea0e3b4",
   "metadata": {},
   "source": [
    "Now we will load the data we will embed for contextual prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "578d87b3-348c-4daf-a0cc-7076b60ed17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.url import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d1af700-e0ef-4584-85f5-13d55e71857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://aws.amazon.com/codewhisperer/faqs/\",\n",
    "    \"https://aws.amazon.com/sagemaker/faqs/\",\n",
    "]\n",
    "headers={\"ssl_verify\":\"False\"}\n",
    "loader = UnstructuredURLLoader(urls=urls,headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183567f-e741-4808-92d2-1990bdb590b1",
   "metadata": {},
   "source": [
    "We will now install the `faiss-cpu` library\n",
    "\n",
    "`faiss-cpu` provides efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a library developed by Facebook AI that allows for efficient similarity search and clustering of dense vectors. So, given a set of vectors(in this case a vector representation of a document i.e. an embedding), we can index them using Faiss — then using another vector (the query vector), we search for the most similar vectors within the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d796a5c-26cc-45a4-bf88-8f786a0d13b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c860e5-e54c-4490-a797-a420020588de",
   "metadata": {},
   "source": [
    "We will now create an index of our documents using the VectorstoreIndexCreator. This index will allow us to perform efficient similarity searches on our documents.\n",
    "\n",
    "The VectorstoreIndexCreator is a utility that helps us create an index of our documents. It uses the embeddings of the documents to create the index. The embeddings are dense vectors that represent the documents. The index allows us to perform efficient similarity searches on the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9083c77-5373-4f9a-88d0-b74052d26a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma, AtlasDB, FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader,CSVLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")\n",
    "\n",
    "index_creator = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=embeddings,\n",
    "    text_splitter = text_splitter\n",
    ")\n",
    "index = index_creator.from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e68ef0-58de-4770-a7c9-7871d487ec56",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2.d Querying t2t llm using RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea34f918-da57-465b-90b9-ec087513b61c",
   "metadata": {},
   "source": [
    "Let's test our index by querying it with a sample question.\n",
    "\n",
    "The `index.query` function is used to perform a similarity search on the index. It takes a question and a language model as input, and returns the most similar documents in the index. After the relevant documents are retrieved, the LLM can be used to generate a coherent and contextually relevant answer based on the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6530046-a0d0-410e-80f4-f01680426646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all instances supported in SageMaker'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(question=query, llm=sm_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c72ba4-7110-42b2-a7d2-099f0e90d49f",
   "metadata": {},
   "source": [
    "we will create a document search object using the FAISS vector store and our documents. This will allow us to perform similarity searches on our documents. Using this we retrieve the top 3 most similar docs to our query.\n",
    "\n",
    "The `FAISS.from_documents` function is used to create a FAISS vector store from our documents. The embeddings of the documents are used to create the vector store. The vector store allows us to perform efficient similarity searches on the documents.\n",
    "\n",
    "The `docsearch.similarity_search` function is used to perform a similarity search on the documents. It takes a query and a number of results to return as input, and returns the most similar documents in the vector store. The query is converted into an embedding and this embedding is then compared with the embeddings of the documents in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35208bcc-4aad-46b2-8e37-da7b4b7fd712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Q: Which instances can I use with Managed Spot Training?\\n\\nManaged Spot Training can be used with all instances supported in SageMaker.\\n\\nQ: Which Regions are supported with Managed Spot Training?', metadata={'source': 'https://aws.amazon.com/sagemaker/faqs/', 'start_index': 46752}),\n",
       " Document(page_content='Q: When should I use Managed Spot Training?', metadata={'source': 'https://aws.amazon.com/sagemaker/faqs/', 'start_index': 45014}),\n",
       " Document(page_content='Q: Why should I use SageMaker Serverless Inference?', metadata={'source': 'https://aws.amazon.com/sagemaker/faqs/', 'start_index': 55822})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "splitdocuments = text_splitter.split_documents(documents)\n",
    "docsearch = FAISS.from_documents(splitdocuments, embeddings)\n",
    "docs = docsearch.max_marginal_relevance_search(query, k=3)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abcf5a7-c920-4c41-9b74-c138805e24fc",
   "metadata": {},
   "source": [
    "Finally, we will use our question-answering chain to answer our query using the documents we found.\n",
    "\n",
    "The `chain` function is used to apply our question-answering chain to our query and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7957ac35-0ab4-4945-8b5b-ff7dcbe148fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'all instances supported in SageMaker'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c4e0a-c187-4571-9119-095b01863a97",
   "metadata": {},
   "source": [
    "Now let's try this with some data from our retail demo store. To do this upload the retail_items.csv file in the data provided to an s3 bucket for retrieval by this notebook and replace 'retail_data_s3_path' with your S3 path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb0ace0c-8fa5-4693-a824-696be3e4986f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://mysagebucket-4590283737/RAGFiles/retail_items.csv to rag_data/retail_items.csv\n"
     ]
    }
   ],
   "source": [
    "retail_data_s3_path = \"s3://mysagebucket-4590283737/RAGFiles/\"\n",
    "!mkdir rag_data\n",
    "!aws s3 cp --recursive $retail_data_s3_path rag_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3ae5d-af4b-4ace-8ec5-2a3bb61f058c",
   "metadata": {},
   "source": [
    "Now let's preprocess the data in the csv to a format for suitable for documents(this is not prescriptive, just came to this using experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d127ed05-5c0f-49f7-903e-e1626c1f8303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-3991d945ff00>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['description'] = df.apply(lambda row: f\"{row['name']} is a {row['style']} in the {row['category']} category. Description: {row['description']} with a Price of ${row['price']} and Current stock is {row['current_stock']}.\", axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sans Pareil Scarf is a scarf in the apparel ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chef Knife is a kitchen in the housewares cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gainsboro Jacket is a jacket in the apparel ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High Definition Speakers is a speaker in the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiffy Sandals is a sandals in the footwear ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  Sans Pareil Scarf is a scarf in the apparel ca...\n",
       "1  Chef Knife is a kitchen in the housewares cate...\n",
       "2  Gainsboro Jacket is a jacket in the apparel ca...\n",
       "3  High Definition Speakers is a speaker in the e...\n",
       "4  Spiffy Sandals is a sandals in the footwear ca..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('rag_data/retail_items.csv')\n",
    "\n",
    "processed_df=df[['description']]\n",
    "processed_df['description'] = df.apply(lambda row: f\"{row['name']} is a {row['style']} in the {row['category']} category. Description: {row['description']} with a Price of ${row['price']} and Current stock is {row['current_stock']}.\", axis=1)\n",
    "\n",
    "processed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42acdd8e-de04-4118-bc31-653c823e7fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_df[['description']].to_csv(\"rag_data/processed_retail_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e246a403-6acd-4392-958f-02c75af52174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retail_data_loader = CSVLoader(file_path=\"rag_data/processed_retail_data.csv\")\n",
    "retail_data_documents = retail_data_loader.load() #we now load the data into documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f77bd41-3cc0-4064-983a-d4b44ca5e6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter( #we create a text splitter to split the documents into chunks\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")\n",
    "retail_data_index_creator = VectorstoreIndexCreator( #we create an index creator to create an index of the embeddings of the documents\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=embeddings,\n",
    "    text_splitter=text_splitter,\n",
    ")\n",
    "retail_data_index = retail_data_index_creator.from_loaders([retail_data_loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f288b-3c3e-4e0c-b7b1-fd22ca1fffef",
   "metadata": {},
   "source": [
    "Now let's query our base model without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "680f019b-aab3-4297-85d4-53da290d55e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retail_query=\"What is the price and stock of Sans Pareil scarf?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69d3da19-799f-4cd9-8687-7d82920e74ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'not enough information'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"input_documents\": input_documents, \"question\": retail_query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba75966-c4cf-4c0e-94d6-718ff87c9dbe",
   "metadata": {},
   "source": [
    "And querying using RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "daa41875-c2e3-40a3-a334-5f7c4a53c429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$114.99 and Current stock is 6'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data_index.query(question=retail_query, llm=sm_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568041ec-0ae4-4fe8-be31-11c553219ac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 3\n",
    "---\n",
    "<h1><b> Prompt Engineering </b></h1>\n",
    "\n",
    "<h2>\n",
    "   Explore Prompt Engineering Techniques\n",
    "    \n",
    "</h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ec997-f876-4d08-b40d-3e8e99dcbb89",
   "metadata": {},
   "source": [
    "### **Prompting Principles**\n",
    "\n",
    "- [3.a Write clear and specific instructions.](#3.a-Write-clear-and-specific-instructions)\n",
    "- [3.b Give the model time to “think”.](#3.b-Give-the-model-time-to-\"think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f633b-1a15-4a4d-a394-54a625056705",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **3.a Tactics for 'Write clear and specific instructions'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5f20c-a1eb-41d4-b501-e9c185e7d184",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac876030-4ab2-4f37-a7ec-156f97ed14af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CodeWhisperer is an AI-powered coding companion designed to assist developers in real-time within their Integrated Development Environment (IDE).']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"CodeWhisperer is an AI-powered coding companion designed to assist developers in \\\n",
    "real-time within their Integrated Development Environment (IDE). \\\n",
    "It provides single-line or full-function code suggestions based on natural language comments, \\\n",
    "such as specific tasks or instructions. The suggestions are generated from large language models \\\n",
    "trained on billions of lines of code, including Amazon and open-source code. \\\n",
    "Developers can quickly accept, review, or continue writing their code, \\\n",
    "with the ability to edit suggestions to ensure accuracy. CodeWhisperer also offers \\\n",
    "specialized training for AWS APIs and helps in improving application security by detecting vulnerabilities. \\\n",
    "It supports multiple programming languages and can be used across various IDEs. \\\n",
    "The service also emphasizes responsible AI use, including bias filtering and \\\n",
    "tracking of suggestions that might resemble open-source training data.\"\n",
    "\n",
    "delimiter_prompt = f\"Summarize the text delimited by triple backticks into only a single sentence:\\n```{text}```\"\n",
    "\n",
    "get_completion(delimiter_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed018d-cdc3-4181-a5e2-5a121812065c",
   "metadata": {},
   "source": [
    "#### Tactic 2: Ask for a structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd271e8c-978e-400a-b470-425dff41692f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CodeWhisperer is an AI-powered coding companion designed to assist developers in real-time within their Integrated Development Environment (IDE). It provides single-line or full-function code suggestions based on natural language comments, such as specific tasks or instructions. The suggestions are generated from large language models trained on billions of lines of code, including Amazon and open-source code. Developers can quickly accept, review, or continue writing their code, with the ability to edit suggestions to ensure accuracy. CodeWhisperer also offers specialized training for AWS APIs and helps in improving application security by detecting vulnerabilities. It supports multiple programming languages and can be used across various IDEs. The service also emphasizes responsible AI use, including bias filtering and tracking of suggestions that might resemble open-source training data.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"Summarise the key features of CodeWhisperer outlined in the text delimited by triple backticks\\\n",
    "into a single sentence. And output them in JSON form with key being a name of the feature and value \\\n",
    "being the description.For example,'feature1':'description1'\\\n",
    "```{text}```\"\n",
    "\n",
    "get_completion(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb080f-389d-4fae-ab5f-814d6cc8e56d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tactic 3: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dca049e5-b1c8-4c33-ac6c-96cee55a0d81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Step 1 - Choose your IDE Step 2 - Install or update your IDE (if applicable) Step 3 - Install or update the AWS Toolkit (if applicable) Step 4 - Choose your authentication method Step 5 - Set up your Builder ID, IAM Identity Center, or IAM credentials']\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Before you use CodeWhisperer for the first time, you do the following: \\\n",
    "Choose your IDE. Install or update your IDE (if applicable). \\\n",
    "Install or update the AWS Toolkit (if applicable). Choose your authentication method.\\\n",
    "Set up your Builder ID, IAM Identity Center, or IAM credentials.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ecdf96b-229f-4e36-baca-acbadc45138d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No steps provided']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"CodeWhisperer is an AI-powered coding companion designed to assist developers in \\\n",
    "real-time within their Integrated Development Environment (IDE). \\\n",
    "It provides single-line or full-function code suggestions based on natural language comments, \\\n",
    "such as specific tasks or instructions. The suggestions are generated from large language models \\\n",
    "trained on billions of lines of code, including Amazon and open-source code. \\\n",
    "Developers can quickly accept, review, or continue writing their code, \\\n",
    "with the ability to edit suggestions to ensure accuracy. CodeWhisperer also offers \\\n",
    "specialized training for AWS APIs and helps in improving application security by detecting vulnerabilities. \\\n",
    "It supports multiple programming languages and can be used across various IDEs. \\\n",
    "The service also emphasizes responsible AI use, including bias filtering and \\\n",
    "tracking of suggestions that might resemble open-source training data.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17ce6f-25a3-450e-baee-e9ea279cd687",
   "metadata": {},
   "source": [
    "#### Tactic 4: \"Few-shot\" prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10f1de2b-5c87-4f47-9bed-013c6159748f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grandparent>: The humblest of men is the humblest of all; the proudest of men is the proudest of all; the most mighty of men is the most humble of all; the most mighty of men is the most humble of all.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\n",
    "<grandparent>: The mightiest oak stands tall not because \\\n",
    "it never faced a storm, but because it \\\n",
    "bent and swayed without breaking; the \\\n",
    "most enduring diamond was once mere coal, \\\n",
    "pressured yet unyielding; the brightest stars \\\n",
    "shine after the darkest nights.\n",
    "\n",
    "<child>: Teach me about humility.\n",
    "\"\"\"\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142e0f9-cd45-418b-9177-2b86772957bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **3.b Tactics for 'Give the model time to “think”.'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85886ca4-75a5-462d-acf6-e77346a7bfc0",
   "metadata": {},
   "source": [
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ba3bc4b-7f0b-4cdc-9e78-8c19c90d6e04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CodeWhisperer est un aide à la coding à la base d’AI conçu pour aider les développeurs en temps réel dans leur environnement intégré de développement (IDE). Il fournit des suggestions de coding à la base de lignes ou de fonction complète à partir de commentaires de langue naturale, tels que des tâches ou des instructions. Les suggestions sont générées par des grandes modèles de langues éducés sur des milliards de lignes de coding, y compris de coding Amazon et de coding libre. Les développeurs peuvent rapidement accepter, revoir ou poursuivre l’écriture de leur coding, avec la possibilité d’editer les suggestions pour assurer l’exactitude. CodeWhisperer offre également une formation spécialisée pour les APIs de AWS et aide à améliorer la sécurité des applications en détectant les vulnérabilités. Il appuie plusieurs langues de programmation et peut être utilisé dans différentes IDEs. Le service souligne également l’utilisation responsable de l’AI, y compris la filtration des écarts et la suivi des suggestions qui ressemblent aux données de l’apprentissage à partir d’une source libre.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"CodeWhisperer is an AI-powered coding companion designed to assist developers in \\\n",
    "real-time within their Integrated Development Environment (IDE). \\\n",
    "It provides single-line or full-function code suggestions based on natural language comments, \\\n",
    "such as specific tasks or instructions. The suggestions are generated from large language models \\\n",
    "trained on billions of lines of code, including Amazon and open-source code. \\\n",
    "Developers can quickly accept, review, or continue writing their code, \\\n",
    "with the ability to edit suggestions to ensure accuracy. CodeWhisperer also offers \\\n",
    "specialized training for AWS APIs and helps in improving application security by detecting vulnerabilities. \\\n",
    "It supports multiple programming languages and can be used across various IDEs. \\\n",
    "The service also emphasizes responsible AI use, including bias filtering and \\\n",
    "tracking of suggestions that might resemble open-source training data.\"\n",
    "# example 1\n",
    "prompt = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "print(\"\\nCompletion for prompt 1:\")\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0aaea-60a2-494c-a5c2-e40d46f0ad6b",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7fde182-2143-4f38-85b6-5e19c5a6b678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124c617-0588-4657-ba30-5b504ef873ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Note that the student's solution is actually not correct.\n",
    "#### We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2cfff45-52e2-41ec-9ac0-6e017a218cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"No, the student's solution is incorrect. The solar panels cost 250x / square foot, not 250x / square foot. The maintenance cost is 100x + 100x + 100x = 450x + 100,000. The total cost is 450x + 100,000 + 100x = 450x + 450x + 100,000.\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following,\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format to outline your answer, break your process into steps, and explain each step\n",
    "Question\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated?\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution. Analyse it step by step when explaining your reasoning why the student's solution is incorrect:\n",
    "\"\"\"\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba046f-b03d-48a9-8532-a74171196da9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a0e18-d996-4839-991c-732dd8c398ac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> IMPORTANT: Clean Up the resources to aviod charges for the resources in use. </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede525b-6d60-4b65-88fa-82efee413885",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "- Delete the endpoints for all the deployed models\n",
    "- Delete the base model image. You can choose to not delete the trained/fine-tuned models from S3 so that you can redeploy them in future. Be aware of the storage charges involved\n",
    "- Shutdown the kernel of this notebook and any active kernels on the other notebooks *(Check the running terminals and kernels icon in the left navigation of SageMaker studio)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "609a5b41-7337-4578-9ea0-d11f5a5c50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model - Delete the SageMaker endpoint and the model stored on S3\n",
    "base_model_predictor.delete_model()\n",
    "base_model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6cfe1b4-1fb8-45a4-805f-73d9b03d17c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_embedding_model_predictor.delete_model()\n",
    "base_embedding_model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76300aec-f665-4c42-ac68-3ddd8bf15a6d",
   "metadata": {},
   "source": [
    "## Release the Notebook Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "205f98bd-e909-4982-aa45-65dd6853a089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a020a-4a44-43c3-a142-abdbc9155ee0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>You have successfully completed the lab session. Do not forget to share your feedback through the below survey. </b>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
